{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-oNmLO-S0k2-"},"outputs":[],"source":["#ResNet 기본 블록 정의\n","\n","import torch\n","import torch.nn as nn\n","\n","class BasicBlock(nn.Module):\n","   def __init__(self, in_channels, out_channels, kernel_size=3):#기본 커널 사이즈 3*3\n","       super(BasicBlock, self).__init__()\n","\n","\n","       #합성곱층 정의\n","       self.c1 = nn.Conv2d(in_channels, out_channels,\n","                           kernel_size=kernel_size, padding=1)\n","       self.c2 = nn.Conv2d(out_channels, out_channels,\n","                           kernel_size=kernel_size, padding=1)\n","\n","       self.downsample = nn.Conv2d(in_channels, out_channels,\n","                                   kernel_size=1)#x의 채널 수를 F(x)와 같게 맞춰주는 역할.\n","                                   #채널의 수가 같으면 downsample 부분이 생략되도록 구현 수정 가능\n","\n","       #배치 정규화층 정의\n","       self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n","       self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n","\n","       self.relu = nn.ReLU()\n","   def forward(self, x):#Conv → BN → ReLU → Conv → BN 구조\n","       #스킵 커넥션을 위해 초기 입력을 저장\n","       x_ = x\n","       #x_를 다운샘플해서 채널 맞춰주고 x와 더한 뒤에 ReLU 활성화\n","\n","       x = self.c1(x)\n","       x = self.bn1(x)\n","       x = self.relu(x)\n","       x = self.c2(x)\n","       x = self.bn2(x)\n","\n","       #합성곱의 결과와 입력의 채널 수를 맞춤\n","       x_ = self.downsample(x_)\n","\n","       #합성곱층의 결과와 저장해놨던 입력값을 더해줌\n","       x += x_\n","       x = self.relu(x)\n","\n","       return x"]},{"cell_type":"code","source":["#ResNet 모델 정의하기\n","\n","class ResNet(nn.Module):\n","   def __init__(self, num_classes=10):#분류할 클래스의 수가 10\n","       super(ResNet, self).__init__()\n","\n","\n","       #기본 블록\n","       self.b1 = BasicBlock(in_channels=3, out_channels=64)\n","       self.b2 = BasicBlock(in_channels=64, out_channels=128)\n","       self.b3 = BasicBlock(in_channels=128, out_channels=256)\n","\n","\n","       #풀링을 최댓값이 아닌 평균값으로\n","       self.pool = nn.AvgPool2d(kernel_size=2, stride=2) #MaxPooling으로 변경 가능\n","\n","       #분류기 #fully connected layer(MLP)\n","       #(생각해보기) 왜 4096일까?\n","       self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n","       self.fc2 = nn.Linear(in_features=2048, out_features=512)\n","       self.fc3 = nn.Linear(in_features=512, out_features=num_classes)\n","\n","       self.relu = nn.ReLU()\n","\n","\n","   def forward(self, x):\n","       #기본 블록과 풀링층을 통과 = 전체 특징 추출 파트\n","       #블록 수 계속 늘려보기\n","       x = self.b1(x)\n","       x = self.pool(x)\n","       x = self.b2(x)\n","       x = self.pool(x)\n","       x = self.b3(x)\n","       x = self.pool(x)\n","\n","\n","       #분류기의 입력으로 사용하기 위해 flatten\n","       x = torch.flatten(x, start_dim=1)\n","\n","       #분류기로 예측값 출력: 최종 출력 생성\n","       x = self.fc1(x)\n","       x = self.relu(x)\n","       x = self.fc2(x)\n","       x = self.relu(x)\n","       x = self.fc3(x)\n","\n","       return x"],"metadata":{"id":"tJ0gS5K90uXR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데이터 전처리부\n","\n","import tqdm\n","\n","from torchvision.datasets.cifar import CIFAR10\n","from torchvision.transforms import Compose, ToTensor\n","from torchvision.transforms import RandomHorizontalFlip, RandomCrop\n","from torchvision.transforms import Normalize\n","from torch.utils.data.dataloader import DataLoader\n","\n","from torch.optim.adam import Adam\n","\n","train_transforms = Compose([\n","   RandomCrop((32, 32), padding=4),  #주변에 4픽셀 추가한 후, 32*32 크기로 랜덤 크롭핑\n","   RandomHorizontalFlip(p=0.5),  #50% 확률로 y축으로 뒤집기\n","   ToTensor(),  #텐서로 변환(픽셀값 범위를 정규화함)\n","   #이미지 정규화(R, G, B 각 채널별)\n","   Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n","])\n","\n","test_transform = Compose([\n","    ToTensor(),\n","    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n","])"],"metadata":{"id":"_zQylPTO43FD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#학습 데이터와 평가 데이터 불러오기\n","#transform = transforms 사용하면서 데이터의 증강이 적용됨.\n","#실제 저장공간에서의 데이터 수가 늘어나나? no. 하지만 매 epoch에서 랜덤한 변화가 생기면서 다양한 모습의 데이터를 볼 수 있음.\n","training_data = CIFAR10(root=\"./\", train=True, download=True, transform=train_transforms)\n","\n","#test데이터는 평가용이므로, 원본 데이터로 측정해야 함.\n","test_data = CIFAR10(root=\"./\", train=False, download=True, transform=test_transform)\n","\n","train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kKSJxGm5gZ7","outputId":"e97c8787-f063-4907-8dae-83b77cd8ca64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:04<00:00, 35.3MB/s]\n"]}]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = ResNet(num_classes=10)\n","model.to(device)"],"metadata":{"id":"GePT9H2d5tRO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef0fa9c4-5bfe-4465-f78d-b95a27cd3295"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (b1): BasicBlock(\n","    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (downsample): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (b2): BasicBlock(\n","    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (b3): BasicBlock(\n","    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU()\n","  )\n","  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n","  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","  (fc3): Linear(in_features=512, out_features=10, bias=True)\n","  (relu): ReLU()\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["lr = 1e-4\n","optim = Adam(model.parameters(), lr=lr)\n","\n","for epoch in range(1):#시간관계상 1, 작동 테스트 후 큰 값으로 변경 바람\n","   iterator = tqdm.tqdm(train_loader)\n","   for data, label in iterator:\n","       # 최적화를 위해 기울기를 초기화\n","       optim.zero_grad()\n","\n","       # 모델의 예측값\n","       preds = model(data.to(device))\n","\n","       # 손실 계산 및 역전파\n","       loss = nn.CrossEntropyLoss()(preds, label.to(device))\n","       loss.backward()\n","       optim.step()\n","\n","       iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n","\n","torch.save(model.state_dict(), \"ResNet.pth\")"],"metadata":{"id":"PMjFduAKEYf1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7773eacb-1b59-45af-8653-5c478940b6d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["epoch:1 loss:0.7609254121780396: 100%|██████████| 1563/1563 [00:42<00:00, 36.48it/s]\n"]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"ResNet.pth\", map_location=device))\n","\n","num_corr = 0\n","\n","with torch.no_grad():\n","   for data, label in test_loader:\n","\n","       output = model(data.to(device))\n","       preds = output.data.max(1)[1]\n","       corr = preds.eq(label.to(device).data).sum().item()\n","       num_corr += corr\n","\n","   print(f\"Accuracy:{num_corr/len(test_data)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WLFTTl0TEfEQ","outputId":"16c636cc-3c21-4d4b-f95f-d70c4976fd15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:0.7628\n"]}]}]}