{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quow1bBasOa7",
        "outputId": "bb437b4d-3c22-45ca-d8dc-5686d9d2a270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 95.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.models.vgg import vgg16\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = vgg16(pretrained=True) #vgg16 모델 객체 생성, ImageNet 데이터셋으로 이미 학습된 것을 가져와 전이학습\n",
        "#초기 가중치의 성능이 좋은 상태이므로, 적은 데이터로도 빠르게 학습할 수 있음\n",
        "\n",
        "fc = nn.Sequential( #분류층을 새롭게 정의함. ImageNet  데이터가 아니라, CIFAR-10 데이터이기 때문에 마지막 레이어는 10개로 나오게 해야함\n",
        "       nn.Linear(512 * 7 * 7, 4096),\n",
        "       nn.ReLU(),\n",
        "       nn.Dropout(), #드롭아웃층 정의\n",
        "       nn.Linear(4096, 4096),\n",
        "       nn.ReLU(),\n",
        "       nn.Dropout(),\n",
        "       nn.Linear(4096, 10),\n",
        "   )\n",
        "\"\"\"\n",
        "(Flatten된 입력: 512 * 7 * 7 = 25088) → FC(4096) → ReLU → Dropout\n",
        "→ FC(4096) → ReLU → Dropout\n",
        "→ FC(10) → 출력\n",
        "\"\"\"\n",
        "model.classifier = fc #VGG의 classifier 부분을 우리가 만든 것으로 덮어씀\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LpBHRkAbsUom"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomCrop, Normalize\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "#cifar-10 데이터셋의 이미지 크기는 32*32인데, ImageNet은 224*224임. 전이학습된 걸 사용하기 위해 이미지를 resize함\n",
        "train_transforms = Compose([\n",
        "   Resize(224),\n",
        "   RandomCrop((224, 224), padding=4),#resize 후 crop을 권장함. crop 후 resize하면 정보 손실이 크기 때문.\n",
        "   RandomHorizontalFlip(p=0.5),\n",
        "   ToTensor(),\n",
        "   Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))#이전 실습에서 얻은 값..\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test데이터용 전처리\n",
        "test_transforms = Compose([\n",
        "    Resize(224),  # 또는 Resize((224, 224))도 가능\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
        "])"
      ],
      "metadata": {
        "id": "zGD4pVtOt9yG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AhSJb-B1P37",
        "outputId": "949fe28b-6d38-4500-c6f8-f6d244c3fafb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 30.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=train_transforms)\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=test_transforms)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tID-VPsUQuiS",
        "outputId": "4db4817d-cb36-40ce-d41e-c018776667cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:1 loss:0.2635610103607178: 100%|██████████| 1563/1563 [14:16<00:00,  1.83it/s]\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-4 #전이학습에서는 보통 학습률을 적게 설정함. 1e-4, 1e-5 ...\n",
        "optim = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(1):#epoch 수정하기 -> 예: 5\n",
        "   iterator = tqdm.tqdm(train_loader) #학습 진행바 보이도록 출\n",
        "   for data, label in iterator:\n",
        "       optim.zero_grad()#매 batch마다 gradient 초기화(전이학습 된 가중치가 초기화되는 게 아님!)\n",
        "       #gradient를 초기화하지 않으면  gradient가 배치마다 누적되기 때문에 원치 않는 결과가 나옴.\n",
        "\n",
        "       preds = model(data.to(device)) # 모델의 예측값 출력\n",
        "\n",
        "       loss = nn.CrossEntropyLoss()(preds, label.to(device))#손실 계산\n",
        "       loss.backward()#역전파\n",
        "       optim.step()#가중치 업데이트\n",
        "\n",
        "       # tqdm이 출력할 문자열 지정\n",
        "       iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"CIFAR_pretrained.pth\") # 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"CIFAR_pretrained.pth\", map_location=device))\n",
        "\n",
        "num_corr = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "   for data, label in test_loader:\n",
        "\n",
        "       output = model(data.to(device))\n",
        "       preds = output.data.max(1)[1]\n",
        "       corr = preds.eq(label.to(device).data).sum().item()\n",
        "       num_corr += corr\n",
        "\n",
        "   print(f\"Accuracy:{num_corr/len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWAN5XZyAd6A",
        "outputId": "bc3900bc-f20d-43b5-d308-3566366980a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-1f03128bc2c8>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"CIFAR_pretrained.pth\", map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:0.8934\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}